{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguishing comparison in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_extraction import ExtractMiddlePart, ExtractRawSentence\n",
    "from infersent.infersent_feature import initialize_infersent, InfersentFeature\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/data.csv\")\n",
    "test = pd.read_csv(\"data/held-out-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = make_pipeline(ExtractRawSentence(), CountVectorizer(), XGBClassifier(n_jobs=-1, n_estimators=1000))\n",
    "fitted = pl.fit(train, train['most_frequent_label'].values)\n",
    "predicted = fitted.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER      0.643     0.553     0.594       273\n",
      "       WORSE      0.491     0.235     0.318       119\n",
      "        NONE      0.839     0.919     0.877      1048\n",
      "\n",
      "    accuracy                          0.793      1440\n",
      "   macro avg      0.658     0.569     0.597      1440\n",
      "weighted avg      0.773     0.793     0.777      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['most_frequent_label'].values, predicted, labels=['BETTER', 'WORSE', 'NONE'], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle part of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = make_pipeline(ExtractMiddlePart(), CountVectorizer(), XGBClassifier(n_jobs=-1, n_estimators=1000))\n",
    "fitted = pl.fit(train, train['most_frequent_label'].values)\n",
    "predicted = fitted.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER      0.765     0.751     0.758       273\n",
      "       WORSE      0.542     0.328     0.408       119\n",
      "        NONE      0.903     0.948     0.925      1048\n",
      "\n",
      "    accuracy                          0.859      1440\n",
      "   macro avg      0.736     0.675     0.697      1440\n",
      "weighted avg      0.847     0.859     0.850      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['most_frequent_label'].values, predicted, labels=['BETTER', 'WORSE', 'NONE'], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InferSent + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sentences = ExtractRawSentence().transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'models.BLSTMEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/nick/anaconda3/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "Found 14943(/16494) words with glove vectors\n",
      "Vocab size : 14943\n"
     ]
    }
   ],
   "source": [
    "infersent = initialize_infersent(full_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/Jupyter/ML/Final_project/models.py:206: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences[stidx:stidx + bsize]), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "pl = make_pipeline(ExtractRawSentence(), InfersentFeature(infersent), XGBClassifier(n_jobs=-1, n_estimators=1000))\n",
    "fitted = pl.fit(train, train['most_frequent_label'].values)\n",
    "predicted = fitted.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER      0.708     0.586     0.641       273\n",
      "       WORSE      0.556     0.210     0.305       119\n",
      "        NONE      0.849     0.947     0.895      1048\n",
      "\n",
      "    accuracy                          0.817      1440\n",
      "   macro avg      0.704     0.581     0.614      1440\n",
      "weighted avg      0.798     0.817     0.798      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['most_frequent_label'].values, predicted, labels=['BETTER', 'WORSE', 'NONE'], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle part of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_part = ExtractMiddlePart().transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "Found 6021(/6555) words with glove vectors\n",
      "Vocab size : 6021\n"
     ]
    }
   ],
   "source": [
    "infersent = initialize_infersent(middle_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = make_pipeline(ExtractMiddlePart(), InfersentFeature(infersent), XGBClassifier(n_jobs=-1, n_estimators=1000))\n",
    "fitted = pl.fit(train, train['most_frequent_label'].values)\n",
    "predicted = fitted.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER      0.768     0.751     0.759       273\n",
      "       WORSE      0.553     0.353     0.431       119\n",
      "        NONE      0.901     0.943     0.921      1048\n",
      "\n",
      "    accuracy                          0.858      1440\n",
      "   macro avg      0.740     0.682     0.704      1440\n",
      "weighted avg      0.847     0.858     0.850      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['most_frequent_label'].values, predicted, labels=['BETTER', 'WORSE', 'NONE'], digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
